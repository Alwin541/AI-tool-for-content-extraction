{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOK0EFwCd+Nj0bM+MtmOuaY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install google-generativeai arxiv python-docx\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HD9nRAB3zH-P","executionInfo":{"status":"ok","timestamp":1754541181558,"user_tz":-330,"elapsed":4018,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}},"outputId":"d60c6f91-1134-40ce-9277-01dd6fd8d52c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n","Requirement already satisfied: arxiv in /usr/local/lib/python3.11/dist-packages (2.2.0)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n","Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.11/dist-packages (from arxiv) (6.0.11)\n","Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.7.14)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"]}]},{"cell_type":"code","source":["import google.generativeai as genai\n","\n","# Paste your Gemini API key here\n","genai.configure(api_key=\"AIzaSyCoY6cL7O0WK6Z1W4X00C4Sk9jGlmt2f6M\")\n","\n","# Load Gemini Pro model\n","model = genai.GenerativeModel('gemini-1.5-flash-latest') # Changed from 'gemini-pro'"],"metadata":{"id":"VCKyoEK3zKTF","executionInfo":{"status":"ok","timestamp":1754541303374,"user_tz":-330,"elapsed":45,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import arxiv\n","\n","def fetch_arxiv(query, max_results=3):\n","    search = arxiv.Search(\n","        query=query,\n","        max_results=max_results,\n","        sort_by=arxiv.SortCriterion.Relevance\n","    )\n","    papers = []\n","    for result in search.results():\n","        papers.append({\n","            \"title\": result.title,\n","            \"summary\": result.summary,\n","            \"url\": result.entry_id\n","        })\n","    return papers\n","\n","# ðŸ”Ž Example usage\n","query = input(\"enter text\")\n","papers = fetch_arxiv(query)\n","\n","# Display summaries\n","for p in papers:\n","    print(f\"ðŸ”¸ {p['title']}\\n{p['url']}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Gt70zOczM8G","executionInfo":{"status":"ok","timestamp":1754541585543,"user_tz":-330,"elapsed":22592,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}},"outputId":"73f386d9-77ff-4024-8f6c-de2c8155975a"},"execution_count":29,"outputs":[{"name":"stdout","output_type":"stream","text":["enter textdeep image prior\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-574496329.py:10: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n","  for result in search.results():\n"]},{"output_type":"stream","name":"stdout","text":["ðŸ”¸ Event-horizon-scale Imaging of M87* under Different Assumptions via Deep Generative Image Priors\n","http://arxiv.org/abs/2406.02785v2\n","\n","ðŸ”¸ The Spectral Bias of the Deep Image Prior\n","http://arxiv.org/abs/1912.08905v1\n","\n","ðŸ”¸ Using Deep Image Prior to Assist Variational Selective Segmentation Deep Learning Algorithms\n","http://arxiv.org/abs/2112.00793v1\n","\n"]}]},{"cell_type":"code","source":["def summarize_with_gemini(text):\n","    prompt = f\"\"\"\n","You are a technical assistant. Summarize the following academic paper abstracts clearly and concisely. Use proper formatting and cite the original sources if available.\n","\n","Text:\n","{text}\n","\"\"\"\n","    response = model.generate_content(prompt)\n","    return response.text\n","\n","# Combine all summaries into one input\n","combined_text = \"\\n\\n\".join([f\"{p['title']}\\n{p['summary']}\" for p in papers])\n","\n","# Get summary from Gemini\n","summary = summarize_with_gemini(combined_text)\n","print(summary)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"nL1ldQ0rzR2M","executionInfo":{"status":"ok","timestamp":1754541594038,"user_tz":-330,"elapsed":3977,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}},"outputId":"406035c2-5a9e-4642-9278-893548101011"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["**Paper 1:**\n","\n","**Title:** Event-horizon-scale Imaging of M87* under Different Assumptions via Deep Generative Image Priors\n","\n","**Summary:** This paper presents a Bayesian inference framework for reconstructing images from Event Horizon Telescope (EHT) data of the M87* black hole.  The framework uses score-based priors derived from deep generative models, allowing for flexible control over the reconstruction process by incorporating different assumptions about the image statistics.  The authors demonstrate how varying the prior influences the reconstructed image features and uncertainty, using both simulated and real EHT data of M87*.  The study highlights the impact of prior selection on the final image.\n","\n","**(Note:  No specific citation provided in the prompt.)**\n","\n","\n","**Paper 2:**\n","\n","**Title:** The Spectral Bias of the Deep Image Prior\n","\n","**Summary:** This paper investigates the \"deep image prior,\" a property of convolutional encoder-decoder networks where the network architecture acts as an implicit prior for natural images.  The authors analyze the optimization trajectories of the deep image prior during image denoising, showing that convolutional layers decouple image frequency components, fitting lower frequencies first.  This low-frequency prior is shown to be analogous to a low-pass filter, explaining why early stopping during training improves denoising.  The work extends previous findings on the Gaussian process equivalence of the deep image prior at initialization.\n","\n","**(Note:  No specific citation provided in the prompt.)**\n","\n","\n","**Paper 3:**\n","\n","**Title:** Using Deep Image Prior to Assist Variational Selective Segmentation Deep Learning Algorithms\n","\n","**Summary:**  This paper proposes to integrate the \"deep image prior\" into traditional variational segmentation algorithms.  The deep image prior provides implicit regularization, replacing explicit regularization terms typically used to enforce solution smoothness. While the standalone deep image prior is only effective for a single image, this approach aims to leverage its implicit regularization while maintaining the ability to predict future images within a more general learning framework.\n","\n","**(Note:  No specific citation provided in the prompt.)**\n","\n"]}]},{"cell_type":"code","source":["from docx import Document\n","\n","def save_to_docx(text, filename=\"Research_Summary.docx\"):\n","    doc = Document()\n","    doc.add_heading(\"Automated Research Summary\", 0)\n","    doc.add_paragraph(text)\n","    doc.save(filename)\n","    print(f\"âœ… Saved as {filename}\")\n","\n","save_to_docx(summary)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3XVqMqczWAE","executionInfo":{"status":"ok","timestamp":1754541455031,"user_tz":-330,"elapsed":40,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}},"outputId":"f9fba8b7-3f31-46e0-b692-e0ad5feca8ab"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Saved as Research_Summary.docx\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"Research_Summary.docx\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"WHNAMukIzYbS","executionInfo":{"status":"ok","timestamp":1754541458273,"user_tz":-330,"elapsed":15,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}},"outputId":"a01cb212-758f-4209-ee04-cc9b1dfadad8"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b46bd562-c5db-4547-af2c-bee38ae0657c\", \"Research_Summary.docx\", 37504)"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"2973b460"},"source":["Let's list the available models to find one that can be used for generating content."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":728},"id":"c757e73a","executionInfo":{"status":"ok","timestamp":1754541287359,"user_tz":-330,"elapsed":3871,"user":{"displayName":"Alwin Joseph","userId":"02375479343022114979"}},"outputId":"6d814be0-76b2-44d7-c5d0-3d9578c07961"},"source":["for m in genai.list_models():\n","  if 'generateContent' in m.supported_generation_methods:\n","    print(m.name)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["models/gemini-1.5-pro-latest\n","models/gemini-1.5-pro-002\n","models/gemini-1.5-pro\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-flash\n","models/gemini-1.5-flash-002\n","models/gemini-1.5-flash-8b\n","models/gemini-1.5-flash-8b-001\n","models/gemini-1.5-flash-8b-latest\n","models/gemini-2.5-pro-preview-03-25\n","models/gemini-2.5-flash-preview-05-20\n","models/gemini-2.5-flash\n","models/gemini-2.5-flash-lite-preview-06-17\n","models/gemini-2.5-pro-preview-05-06\n","models/gemini-2.5-pro-preview-06-05\n","models/gemini-2.5-pro\n","models/gemini-2.0-flash-exp\n","models/gemini-2.0-flash\n","models/gemini-2.0-flash-001\n","models/gemini-2.0-flash-exp-image-generation\n","models/gemini-2.0-flash-lite-001\n","models/gemini-2.0-flash-lite\n","models/gemini-2.0-flash-preview-image-generation\n","models/gemini-2.0-flash-lite-preview-02-05\n","models/gemini-2.0-flash-lite-preview\n","models/gemini-2.0-pro-exp\n","models/gemini-2.0-pro-exp-02-05\n","models/gemini-exp-1206\n","models/gemini-2.0-flash-thinking-exp-01-21\n","models/gemini-2.0-flash-thinking-exp\n","models/gemini-2.0-flash-thinking-exp-1219\n","models/gemini-2.5-flash-preview-tts\n","models/gemini-2.5-pro-preview-tts\n","models/learnlm-2.0-flash-experimental\n","models/gemma-3-1b-it\n","models/gemma-3-4b-it\n","models/gemma-3-12b-it\n","models/gemma-3-27b-it\n","models/gemma-3n-e4b-it\n","models/gemma-3n-e2b-it\n","models/gemini-2.5-flash-lite\n"]}]}]}